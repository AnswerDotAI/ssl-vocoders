{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wnakata/lightning-vocoders/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wnakata/lightning-vocoders/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2Model: ['quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_q.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from lightning_vocoders.models.hifigan.lightning_module import HiFiGANLightningModule\n",
    "lightning_module = HiFiGANLightningModule.load_from_checkpoint(\"../tb_logs/lightning_logs/version_159/checkpoints/epoch=9-step=29480.ckpt\")\n",
    "from lightning_vocoders.models.hifigan.hifigan import Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_cfg = lightning_module.cfg.model.generator\n",
    "generator = Generator(generator_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_input_channels': 768, 'upsample_rates': [7, 7, 3, 3], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [15, 15, 7, 7], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'resblock': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 22050])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "generator_cfg.upsample_rates = [7,7,3,3]\n",
    "generator_cfg.upsample_kernel_sizes = [15,15,7,7]\n",
    "generator = Generator(generator_cfg)\n",
    "generator(torch.randn((1,50,768))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 80/16360 [00:00<00:45, 358.50it/s]\n",
      "  0%|          | 80/16040 [00:05<18:36, 14.30it/s]\n",
      "  1%|          | 80/15720 [00:05<18:13, 14.31it/s]\n",
      "  1%|          | 80/15400 [00:05<17:52, 14.29it/s]\n",
      "  1%|          | 80/15080 [00:05<17:29, 14.29it/s]\n",
      "  1%|          | 80/14760 [00:05<17:08, 14.27it/s]\n",
      "  1%|          | 80/14440 [00:05<16:45, 14.28it/s]\n",
      "  1%|          | 80/14120 [00:05<16:25, 14.25it/s]\n",
      "  1%|          | 80/13800 [00:05<16:02, 14.26it/s]\n",
      "  1%|          | 80/13480 [00:05<15:39, 14.27it/s]\n",
      "  1%|          | 80/13160 [00:05<15:16, 14.28it/s]\n",
      "  1%|          | 80/12840 [00:05<14:54, 14.26it/s]\n",
      "  1%|          | 80/12520 [00:05<14:31, 14.27it/s]\n",
      "  1%|          | 80/12200 [00:05<14:10, 14.25it/s]\n",
      "  1%|          | 80/11880 [00:05<13:47, 14.26it/s]\n",
      "  1%|          | 80/11560 [00:05<13:26, 14.23it/s]\n",
      "  0%|          | 10/11240 [00:00<14:13, 13.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m start \u001b[39m=\u001b[39m \u001b[39m16_000\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m50\u001b[39m \u001b[39m*\u001b[39m i\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(start,\u001b[39m17_000\u001b[39m)):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mif\u001b[39;00m lightning_module\u001b[39m.\u001b[39mpreprocessor\u001b[39m.\u001b[39mssl_model(input_values\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m,j)\u001b[39m.\u001b[39;49mcuda())\u001b[39m.\u001b[39mlast_hidden_state\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m i:\n\u001b[1;32m      8\u001b[0m         lengths\u001b[39m.\u001b[39mappend(j )\n\u001b[1;32m      9\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lengths = []\n",
    "lightning_module.preprocessor.ssl_model.eval()\n",
    "for i in range(2,50):\n",
    "    start = 16_000//50 * i\n",
    "    for j in tqdm(range(start,17_000)):\n",
    "        if lightning_module.preprocessor.ssl_model(input_values=torch.randn(1,j).cuda()).last_hidden_state.size(1) == i:\n",
    "            lengths.append(j )\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[720,\n",
       " 1040,\n",
       " 1360,\n",
       " 1680,\n",
       " 2000,\n",
       " 2320,\n",
       " 2640,\n",
       " 2960,\n",
       " 3280,\n",
       " 3600,\n",
       " 3920,\n",
       " 4240,\n",
       " 4560,\n",
       " 4880,\n",
       " 5200,\n",
       " 5520]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 400, 720, 1040, 1360, 1680, 2000, 2320, 2640, 2960]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_length(x):\n",
    "    return 16_000//50 * x + 80\n",
    "[get_length(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning_module.preprocessor.ssl_model(input_values=torch.randn(1,get_length(49)).cuda()).last_hidden_state.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_values': [array([ 0.15781322, -1.3593025 ,  0.07017981, ...,  0.6999978 ,\n",
       "        0.65397877,  0.6198929 ], dtype=float32)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning_module.preprocessor.ssl_prepreocessor(torch.randn(16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 22016])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_cfg.upsample_rates = [8,8,2,2]\n",
    "generator_cfg.upsample_kernel_sizes = [16,16,8,8]\n",
    "generator = Generator(generator_cfg)\n",
    "generator(torch.randn((1,86,80))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_cfg.upsample_rates = [5,4,4,2,2,2]\n",
    "generator_cfg.upsample_kernel_sizes = [11,8,8,4,4,4]\n",
    "generator = Generator(generator_cfg)\n",
    "generator(torch.randn((1,50,80))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
